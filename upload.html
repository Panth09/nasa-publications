<script type="module">
    import { initializeApp } from 'https://www.gstatic.com/firebasejs/10.7.1/firebase-app.js';
    import {
        getFirestore, collection, doc, writeBatch,
        serverTimestamp               // <-- NEW
    } from 'https://www.gstatic.com/firebasejs/10.7.1/firebase-firestore.js';

    // ---- YOUR CONFIG (keep it) ----
    const firebaseConfig = {
        apiKey: "AIzaSyDbxPfySgHZq0kE_FbewTnIWioJPxwTqks",
        authDomain: "nasa-bio-engine.firebaseapp.com",
        projectId: "nasa-bio-engine",
        storageBucket: "nasa-bio-engine.firebasestorage.app",
        messagingSenderId: "463317555755",
        appId: "1:463317555755:web:d8f27286a31be14ea0686e",
        measurementId: "G-QN49G284KM"
    };
    const app = initializeApp(firebaseConfig);
    const db  = getFirestore(app);
    window.db = db;               // keep for debugging

    /* --------------------------------------------------------------
       CSV → Object (unchanged, only tiny safety tweaks)
       -------------------------------------------------------------- */
    function parseCSV(text) {
        const lines = text.split('\n');
        const headers = lines[0].split(',').map(h => h.trim());
        const data = [];

        for (let i = 1; i < lines.length; i++) {
            if (!lines[i].trim()) continue;

            const values = [];
            let cur = '';
            let inQuote = false;

            for (let j = 0; j < lines[i].length; j++) {
                const ch = lines[i][j];
                if (ch === '"') inQuote = !inQuote;
                else if (ch === ',' && !inQuote) { values.push(cur.trim()); cur = ''; }
                else cur += ch;
            }
            values.push(cur.trim());

            if (values.length === headers.length) {
                const row = {};
                headers.forEach((h, idx) => row[h] = values[idx]);
                data.push(row);
            }
        }
        return data;
    }

    /* --------------------------------------------------------------
       Helper: safe JSON parse (prevents crash on malformed strings)
       -------------------------------------------------------------- */
    const safeJSON = (str, fallback = []) => {
        if (!str) return fallback;
        try { return JSON.parse(str); }
        catch { return fallback; }
    };

    /* --------------------------------------------------------------
       Logging
       -------------------------------------------------------------- */
    function log(msg, type = 'info') {
        const logDiv = document.getElementById('log');
        logDiv.style.display = 'block';
        const el = document.createElement('div');
        el.className = `log-item ${type}`;
        el.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
        logDiv.appendChild(el);
        logDiv.scrollTop = logDiv.scrollHeight;
    }

    /* --------------------------------------------------------------
       MAIN UPLOAD FUNCTION
       -------------------------------------------------------------- */
    window.uploadData = async function () {
        const fileInput   = document.getElementById('csvFile');
        const btn         = document.getElementById('uploadBtn');
        const progDiv     = document.getElementById('progress');
        const progFill    = document.getElementById('progressFill');
        const progText    = document.getElementById('progressText');

        if (!fileInput.files[0]) return alert('Select a CSV first!');

        btn.disabled = true;
        progDiv.style.display = 'block';
        log('Starting…', 'info');

        try {
            const csvText = await fileInput.files[0].text();
            log('CSV read', 'success');

            const rows = parseCSV(csvText);
            log(`Parsed ${rows.length} rows`, 'success');

            const BATCH = 500;               // Firestore limit
            let uploaded = 0;

            for (let i = 0; i < rows.length; i += BATCH) {
                const batch = writeBatch(db);
                const slice = rows.slice(i, i + BATCH);

                slice.forEach(row => {
                    const ref = doc(collection(db, 'publications'));

                    // ---------- CLEAN / CAST ----------
                    const clean = {
                        // basic strings
                        id:            row.id            ?? '',
                        pmcid:         row.pmcid         ?? '',
                        title:         row.title         ?? '',
                        link:          row.link          ?? '',
                        abstract:      row.abstract      ?? '',
                        content_sample:row.content_sample?? '',
                        ai_response:   row.ai_response   ?? '',
                        ai_role:       row.ai_role       ?? '',
                        ai_model:      row.ai_model      ?? '',
                        ai_confidence: row.ai_confidence ?? '',
                        finish_reason: row.finish_reason ?? '',
                        mission_relevance: row.mission_relevance ?? '',
                        // JSON strings → real arrays / objects
                        key_findings:     safeJSON(row.key_findings, []),
                        research_roles:   safeJSON(row.research_roles, []),
                        research_domains: safeJSON(row.research_domains, []),
                        biological_systems: safeJSON(row.biological_systems, []),
                        space_factors:    safeJSON(row.space_factors, {}),
                        usage_stats:      safeJSON(row.usage_stats, {}),
                        // numbers
                        findings_count:   parseInt(row.findings_count)   || 0,
                        relevance_score:  parseInt(row.relevance_score)  || 0,
                        space_complexity: parseInt(row.space_complexity)|| 0,
                        citations_count:  parseInt(row.citations_count)  || 0,
                        publication_year: row.publication_year ? parseInt(row.publication_year) : null,
                        experiment_duration_days: row.experiment_duration_days ? parseInt(row.experiment_duration_days) : null,
                        // booleans / dates
                        processed:      row.processed === 'true',
                        processed_at:   row.processed_at || null,
                        // **use server timestamp** (most reliable)
                        created_at:     serverTimestamp(),
                        updated_at:     serverTimestamp()
                    };

                    batch.set(ref, clean);
                });

                await batch.commit();
                uploaded += slice.length;

                const pct = Math.round((uploaded / rows.length) * 100);
                progFill.style.width = pct + '%';
                progFill.textContent = pct + '%';
                progText.textContent = `Uploaded ${uploaded} / ${rows.length}`;
                log(`Batch ${Math.floor(i/BATCH)+1} done (${uploaded})`, 'success');
            }

            log('ALL DONE!', 'success');
            progText.textContent = `COMPLETE – ${uploaded} docs`;
            alert('Upload finished – you can now lock down Firestore rules again.');

        } catch (e) {
            log(`ERROR: ${e.message}`, 'error');
            console.error(e);
            alert('Upload failed – see log');
        } finally {
            btn.disabled = false;
        }
    };
</script>